{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "055155ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import myutils\n",
    "importlib.reload(myutils)\n",
    "import myutils as myutils\n",
    "import evaluation\n",
    "importlib.reload(evaluation)\n",
    "\n",
    "import mypytable\n",
    "importlib.reload(mypytable)\n",
    "from mypytable import MyPyTable \n",
    "\n",
    "import myclassifiers\n",
    "importlib.reload(myclassifiers)\n",
    "from myclassifiers import MyNaiveBayesClassifier,\\\n",
    "    MyDummyClassifier\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4d64e",
   "metadata": {},
   "source": [
    "# Analyzing Health Risk Factors \n",
    "### Research Leaders: Sofia Verdie, Fiona Callahan \n",
    "##### **CPSC 322, Fall 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c05ae",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "\n",
    "* describes dataset and classification task implemented \n",
    "* briefly describe findings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e591b8d",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis \n",
    "* info about data \n",
    "* summary stats \n",
    "* data visualizations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f4bca",
   "metadata": {},
   "source": [
    "### Data Preprocessing \n",
    "\n",
    "**Our current dataset: full of 30,000 records**\n",
    "    * We will be pairing this down to 5,000 random samples during classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "46ceab0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  30000\n",
      "Width:  20\n",
      "Length:  21706\n",
      "Width:  20\n"
     ]
    }
   ],
   "source": [
    "# load the data into file \n",
    "our_data = MyPyTable().load_from_file(\"input_data/healthData.csv\")\n",
    "\n",
    "length, width = our_data.get_shape()\n",
    "print(\"Length: \", length)\n",
    "print(\"Width: \", width)\n",
    "\n",
    "# cleaning data: remove rows with missing values in the \"Gender\" column, as well as the CLass label column \n",
    "our_data.remove_rows_with_missing_values(\"Gender\")\n",
    "our_data.remove_rows_with_missing_values(\"Medical Condition\")\n",
    "\n",
    "# replacing other missing values with column avergae: need to do for other columns? \n",
    "our_data.replace_missing_values_with_column_average(\"Glucose\")\n",
    "our_data.replace_missing_values_with_column_average(\"Blood Pressure\")\n",
    "our_data.replace_missing_values_with_column_average(\"Cholesterol\")\n",
    "\n",
    "\n",
    "length, width = our_data.get_shape()\n",
    "print(\"Length: \", length)\n",
    "print(\"Width: \", width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "626542c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attribute         min     max      mid        avg    median\n",
      "--------------  -----  ------  -------  ---------  --------\n",
      "Age             10      89      49.5     54.6841     55\n",
      "LengthOfStay     1      19      10        4.41173     4\n",
      "Glucose         20.32  318.51  169.415  123.735     116.78\n",
      "Cholesterol     95.73  355.27  225.5    213.064     211.76\n",
      "Blood Pressure  74.24  226.38  150.31   140.539     140.539\n"
     ]
    }
   ],
   "source": [
    "# summary stats\n",
    "# can compute based on certain columns: EX: age, blood pressure, etc... \n",
    "# need to add more \n",
    "summary_stats = our_data.compute_summary_statistics([\"Age\", \"LengthOfStay\", \"Glucose\", \"Cholesterol\", \"Blood Pressure\"])\n",
    "summary_stats.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a2fde4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "# reducing size of instances to 5000 for classification \n",
    "\n",
    "np.random.seed(0)\n",
    "scaled_down_indexes = np.random.choice(21706, size=5000, replace=False)\n",
    "table = []\n",
    "for i in range(len(our_data.data)):\n",
    "    if i in scaled_down_indexes:\n",
    "        table.append(our_data.data[i])\n",
    "\n",
    "# data set is now full of 5000 instances [scaled down] - to classify on \n",
    "print(len(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb3432",
   "metadata": {},
   "source": [
    "### Classification Results \n",
    "\n",
    "* using dummy, naive bayes, random forest \n",
    "\n",
    "Keeping Attributes: Age, Gender, Blood Pressure, BMI, Length of Stay, Family History, Cholesterol, Oxygen Saturation, Physical Activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb197f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'BMI' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[162], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# make new data table of just the indexes we want \u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# new structure: the keep list [use in future as header]\u001b[39;00m\n\u001b[0;32m     12\u001b[0m new_table \u001b[38;5;241m=\u001b[39m [[row[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m keep_indexes] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m table]\n\u001b[1;32m---> 15\u001b[0m bmi_index \u001b[38;5;241m=\u001b[39m keep\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBMI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m bp_index \u001b[38;5;241m=\u001b[39m keep\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlood Pressure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m glucose_index \u001b[38;5;241m=\u001b[39m keep\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGlucose\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: 'BMI' is not in list"
     ]
    }
   ],
   "source": [
    "# seems to be most important attributes: but produces horrible accuracy, so scale down ! \n",
    "\n",
    "keep = [\"Age\", \"Gender\", \"Glucose\", \"Blood Pressure\", \"BMI\", \"Oxygen Saturation\", \"LengthOfStay\", \"Cholesterol\", \"Physical Activity\", \"Medical Condition\"]\n",
    "# keep = [\"Blood Pressure\", \"LengthOfStay\", \"Cholesterol\", \"Medical Condition\"]\n",
    "keep_indexes = []\n",
    "for i in keep:\n",
    "    column_index = our_data.column_names.index(i)\n",
    "    keep_indexes.append(column_index)\n",
    "\n",
    "# make new data table of just the indexes we want \n",
    "# new structure: the keep list [use in future as header]\n",
    "new_table = [[row[j] for j in keep_indexes] for row in table]\n",
    "\n",
    "\n",
    "bmi_index = keep.index(\"BMI\")\n",
    "bp_index = keep.index(\"Blood Pressure\")\n",
    "glucose_index = keep.index(\"Glucose\")\n",
    "\n",
    "# now need to discretize: look at utils \n",
    "for row in new_table:\n",
    "    row[bmi_index] = myutils.bin_bmi(float(row[bmi_index]))\n",
    "    row[bp_index]  = myutils.bin_bp(float(row[bp_index]))\n",
    "    row[glucose_index] = myutils.bin_glucose(float(row[glucose_index]))\n",
    "\n",
    "# do i need to normalize? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train/test split \n",
    "# making y_train and y_test \n",
    "y = myutils.make_y_col_lists(keep, \"Medical Condition\", new_table)\n",
    "X = [row[:-1] for row in new_table]\n",
    "X_train, X_test, y_train, y_test = evaluation.train_test_split(X, y)\n",
    "\n",
    "\n",
    "# dummy classifier: \n",
    "dummy_clf = MyDummyClassifier()\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# naive bayes:\n",
    "naive_bayes = MyNaiveBayesClassifier()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# now need to do random forest \n",
    "#random_forest = MyRandomForestClassifier()\n",
    "#random_forest.fit(X_train, y_train)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e217618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier: accuracy =  0.2883582089552239 error rate =  0.7116417910447761\n",
      "Naive Bayes Classifier: accuracy =  0.014925373134328358 error rate =  0.9850746268656716\n"
     ]
    }
   ],
   "source": [
    "# now time to predict: \n",
    "d_accuracy, d_error_rate, y_true_dummy, y_pred_dummy = myutils.cross_val_predict(X_train, y_train, dummy_clf)\n",
    "print(\"Dummy Classifier: accuracy = \", d_accuracy, \"error rate = \", d_error_rate)\n",
    "\n",
    "n_accuracy, n_error_rate, n_true, n_pred = myutils.cross_val_predict(X_train, y_train, naive_bayes)\n",
    "print(\"Naive Bayes Classifier: accuracy = \", n_accuracy, \"error rate = \", n_error_rate)\n",
    "\n",
    "#r_accuracy, r_error_rate, r_true, r_pred = myutils.cross_val_predict(X_train, y_train, random_forest)\n",
    "#print(\"Random Forest Classifier: accuracy = \", r_accuracy, \"error rate = \", r_error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b5391c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ee20e28",
   "metadata": {},
   "source": [
    "### Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c869f0",
   "metadata": {},
   "source": [
    "### Acknowledgements "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
