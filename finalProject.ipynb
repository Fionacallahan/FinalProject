{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "055155ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import myutils\n",
    "importlib.reload(myutils)\n",
    "import myutils as myutils\n",
    "\n",
    "import mypytable\n",
    "importlib.reload(mypytable)\n",
    "from mypytable import MyPyTable \n",
    "\n",
    "import myclassifiers\n",
    "importlib.reload(myclassifiers)\n",
    "from myclassifiers import MyKNeighborsClassifier,\\\n",
    "    MyDummyClassifier\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4d64e",
   "metadata": {},
   "source": [
    "# Analyzing Health Risk Factors \n",
    "### Research Leaders: Sofia Verdie, Fiona Callahan \n",
    "##### **CPSC 322, Fall 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c05ae",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "\n",
    "* describes dataset and classification task implemented \n",
    "* briefly describe findings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e591b8d",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis \n",
    "* info about data \n",
    "* summary stats \n",
    "* data visualizations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f4bca",
   "metadata": {},
   "source": [
    "### Data Preprocessing \n",
    "\n",
    "**Our current dataset: full of 30,000 records**\n",
    "    * We will be pairing this down to 5,000 random samples to then, clean, analyze and classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46ceab0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  30000\n",
      "Width:  20\n",
      "Length:  30000\n",
      "Width:  20\n"
     ]
    }
   ],
   "source": [
    "# load the data into file \n",
    "our_data = MyPyTable().load_from_file(\"input_data/healthData.csv\")\n",
    "\n",
    "length, width = our_data.get_shape()\n",
    "print(\"Length: \", length)\n",
    "print(\"Width: \", width)\n",
    "\n",
    "# cleaning data: remove rows with missing values because there are enough instances \n",
    "# our_data.remove_rows_with_missing_values()\n",
    "# print(len(our_data.data))\n",
    "\n",
    "# can also do this: \n",
    "our_data.replace_missing_values_with_column_average(\"Glucose\")\n",
    "our_data.replace_missing_values_with_column_average(\"Blood Pressure\")\n",
    "\n",
    "length, width = our_data.get_shape()\n",
    "print(\"Length: \", length)\n",
    "print(\"Width: \", width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "626542c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attribute       min    max    mid       avg    median\n",
      "------------  -----  -----  -----  --------  --------\n",
      "Age              10     89   49.5  54.6168         55\n",
      "LengthOfStay      1     19   10     4.41413         4\n"
     ]
    }
   ],
   "source": [
    "# summary stats\n",
    "# can compute based on certain columns: EX: age, blood pressure, etc... \n",
    "# need to add more \n",
    "summary_stats = our_data.compute_summary_statistics([\"Age\", \"LengthOfStay\"])\n",
    "summary_stats.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2fde4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "scaled_down_indexes = np.random.choice(30000, size=5000, replace=False)\n",
    "table = []\n",
    "for i in range(len(our_data.data)):\n",
    "    if i in scaled_down_indexes:\n",
    "        table.append(our_data.data[i])\n",
    "\n",
    "# data set is now full of 5000 instances [scaled down] - to classify on \n",
    "print(len(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb3432",
   "metadata": {},
   "source": [
    "### Classification Results \n",
    "\n",
    "* using dummy, naive bayes, random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee20e28",
   "metadata": {},
   "source": [
    "### Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c869f0",
   "metadata": {},
   "source": [
    "### Acknowledgements "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
